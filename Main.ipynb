{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP7UTKe3RdG52QyAo9dXopY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"3pK_m5B9PB-F"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y5FDYnKyPHO5"},"source":["import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","import torchvision.transforms as T\n","from torchvision import datasets, models, transforms\n","import torchvision.models as models\n","from torch.utils.data import DataLoader\n","from torchvision.utils import make_grid\n","from torch.utils.data import random_split\n","import copy\n","import numpy as np\n","from collections import defaultdict\n","import os\n","\n","# Import necessary PyTorch libraries\n","import torch\n","from torch import nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms, models\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data.sampler import SubsetRandomSampler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ShBCXsJWPHWm"},"source":["from torchvision import datasets, models, transforms\n","\n","data_transforms = transforms.Compose([\n","\n","transforms.RandomResizedCrop(224),\n","\n","transforms.RandomHorizontalFlip(),\n","\n","transforms.ToTensor(),\n","\n","transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n","\n","\n","image_datasets = datasets.ImageFolder('/content/drive/My Drive/예선/',data_transforms) # 폴더에 따라 변경\n","\n","print(image_datasets)\n","class_names = image_datasets.classes # 클래스 출력"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v4OvZOeTjwBd"},"source":["print(class_names)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FL8zU6wrSQRo"},"source":["torch.manual_seed(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JPiwAeoVPHZH"},"source":["train_loader = torch.utils.data.DataLoader(image_datasets, batch_size=32,shuffle = True)\n","\n","inputs, classes = next(iter(train_loader))\n","print(classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s5BKLzDaPHbv"},"source":["model = models.resnet101(pretrained=True)      # pretain resnet- 101 사용       \n","\n","number_of_features =  model.fc.in_features\n","model.fc = nn.Linear(number_of_features, 20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZFX6BPNkPHeP"},"source":["from torch.optim import lr_scheduler\n","import time\n","USE_GPU = True\n","\n","if USE_GPU:\n","    model = model.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6jENiYMqPHgp"},"source":["criterion = nn.CrossEntropyLoss()\n","\n","# specify optimizer same as used earlier\n","optimizer_ft = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","# secify scheduler same as used earlier\n","exp_lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, 'min', patience = 5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EQVDQOKdPHjJ"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vSpQ1-6oLzpP"},"source":["print(len(train_loader.dataset))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-mi_dtF0QFso"},"source":["dataloaders = {}\n","dataset_sizes = {}\n","dataloaders['train'] = train_loader\n","#dataloaders['val'] = test_loader\n","dataset_sizes['train'] = len(train_loader.dataset)\n","#dataset_sizes['val'] = len(test_loader.dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x-uFLh3pQFvH"},"source":["from torch.autograd import Variable\n","def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:               \n","                pass\n","                #model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for data in tqdm(dataloaders[phase]):\n","                x, y = data;\n","                inputs = x.squeeze(0).to(device)\n","                labels = y.to(device)\n","#                 if phase == 'train':\n","#                   inputs, labels_a, labels_b, lam = mixup_data(inputs, labels, 0.4, device)\n","#                   inputs, targets_a, targets_b = Variable(inputs), Variable(labels_a), Variable(labels_b)\n","                  \n","                inputs = inputs.to(device)\n","#                 if phase == 'train':\n","#                   labels_a = labels_a.to(device)\n","#                   labels_b = labels_b.to(device)\n","#                 else:\n","#                   labels = labels.to(device)\n","                labels = labels.to(device)\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","#                     loss_func = mixup_criterion(labels_a,labels_b,lam)\n","                    \n","                    _, preds = torch.max(outputs, 1)\n","                    \n","                    loss = criterion(outputs, labels)\n","#                     if phase=='train':\n","#                       loss = loss_func(criterion,outputs)\n","#                     else:\n","#                         loss = criterion(outputs,labels) \n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","                \n","                #labels11.extend((labels.data).float())\n","                #guesses.extend(preds.float())\n","                #print((labels.data).float())\n","                #print(preds.float())\n","                #predicted_classes = torch.argmax(y_pred, dim=1) == 0\n","                #target_classes = self.get_vector(y_batch)\n","                #target_true += torch.sum(target_classes == 0).float()\n","                #predicted_true += torch.sum(predicted_classes).float()\n","                #correct_true += torch.sum(\n","                #predicted_classes == target_classes * predicted_classes == 0).float()\n","#                 if phase == 'train':\n","#                   running_corrects += lam * preds.eq(labels_a.data).sum() + (1 - lam) * preds.eq(labels_b.data).sum()\n","#                 else:\n","#                     running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","            \n","            if phase == 'train':\n","                scheduler.step(epoch_loss)            \n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","                phase, epoch_loss, epoch_acc))\n","            #recall = correct_true / target_true\n","            #precision = correct_true / predicted_true\n","            #f1_score = 2 * precission * recall / (precision + recall)\n","            #f1_score1 = f1_score(labels11,guesses)\n","            #print(precision)\n","            #print(f1_score1)\n","            # deep copy the model\n","            torch.save(model.state_dict(), '/content/drive/My Drive/대회2/contest_test_final.pth')           \n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","    print(\"fin\")\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FuC51sSRQFxm"},"source":["model_ft = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n","                       num_epochs=30)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h8wB-B3mQFz-"},"source":["model1 = models.resnet101()            \n","\n","number_of_features =  model1.fc.in_features\n","model1.fc = nn.Linear(number_of_features, 20)\n","\n","USE_GPU = True\n","if USE_GPU:\n","    model1 = model1.cuda()\n","    \n","model1.load_state_dict(torch.load(\"/content/drive/My Drive/대회2/contest_10_12_test_tmp1.pth\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YyDchjndQF2H"},"source":["test_transforms1 = transforms.Compose([transforms.Resize(256),\n","                                        transforms.CenterCrop(224),\n","                                        transforms.ToTensor(),\n","                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SkxX6HAevRat"},"source":["image_datasets = datasets.ImageFolder('/content/drive/My Drive/대회2/test123',test_transforms1)\n","\n","#train_size = int(0.8 * len(image_datasets))\n","#test_size = len(image_datasets) - train_size\n","#train_dataset, test_dataset = torch.utils.data.random_split(image_datasets, [train_size, test_size])\n","#train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32,shuffle = True)\n","test_loader = torch.utils.data.DataLoader(image_datasets, batch_size=32,shuffle = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gi_LwA03sWLL"},"source":["#train_size = int(0.8 * len(image_datasets))\n","#test_size = len(image_datasets) - train_size\n","#train_dataset, test_dataset = torch.utils.data.random_split(image_datasets, [train_size, test_size])\n","\n","test_loader = torch.utils.data.DataLoader(image_datasets, batch_size=32,shuffle = False)\n","\n","#nputs, classes = next(iter(train_loader))\n","#print(classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IrfWvgJlA94C"},"source":["labelclass = [3,3,10,11,13, 13,13,13,13,13,13,13,4, 4,4,5,7,7,8,8]\n","labelclass1 = [5,20,20,14,1,6,9,15,16,17,18,20,2,7,11,8,1,20,6,9]\n","print(len(labelclass1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5pDePrjjXsNh"},"source":["import csv\n","\n","with open('/content/drive/My Drive/대회2/output22.tsv', 'wt') as out_file:\n","    tsv_writer = csv.writer(out_file, delimiter='\\t')\n","    for a in range(3997):\n","        tmpstr = str(a)+'.jpg'\n","        tsv_writer.writerow([tmpstr, labelclass[outputList[a]], labelclass1[outputList[a]]])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_tavEjXJp-4g"},"source":["import pandas as pd\n","#dataset = pd.read_csv('/content/drive/My Drive/대회2/test123/test/test.tsv', delimiter='\\t', header=None)\n","dataset = pd.read_csv('/content/drive/My Drive/대회2/output13.tsv', delimiter='\\t', header=None)\n","\n","print(dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QnQs2_DA3q0X"},"source":["import natsort as nt\n","from PIL import Image\n","from torch.autograd import Variable \n","def test_model():\n","    data_transforms = transforms.Compose([transforms.Resize(256),\n","                                        transforms.CenterCrop(224),\n","                                        transforms.ToTensor(),\n","                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n","    #model_ft = torch.load('./models/CustomCNN_model.pth', map_location=device)\n","    \n","    path_test = os.path.join(os.getcwd(), '/content/drive/My Drive/대회2/test123/test')\n","    image_list = nt.natsorted(os.listdir(path_test))\n","    output_list = []\n","    for i, images in enumerate(image_list):\n","        path_test_image = os.path.join(path_test, images)\n","        image = Image.open(path_test_image)\n","        image = data_transforms(image)\n","        image.unsqueeze_(dim=0)\n","        image = Variable(image)\n","        image = image.cuda()\n","        torch.no_grad()\n","        output = model1(image)\n","        output = torch.argmax(output, dim=1)\n","        \n","        output_list.append(output)\n","        \n","    return output_list\n","output = test_model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s1_9Hw1O3q24"},"source":["submission = pd.read_csv('/content/drive/My Drive/대회2/test.tsv')\n","\n","submission.digit = torch.cat(output).detach().cpu().numpy()\n","submission.to_csv('/content/drive/My Drive/대회2/output12.tsv', index=False, header=None, sep='\\t')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C1jPMREq3q5a"},"source":["print(torch.cat(output).detach().cpu().numpy())\n","outputList = torch.cat(output).detach().cpu().numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r4K8qIr7xUUp"},"source":["with torch.no_grad():\n","  for data, target in test_loader:\n","    # move tensors to GPU if CUDA is available\n","    if train_on_gpu:\n","      data, target = data.cuda(), target.cuda()          \n","      ## For 10-crop Testing\n","      bs, ncrops, c, h, w = data.size()\n","      # forward pass: compute predicted outputs by passing inputs to the model\n","      temp_output = model(data.view(-1, c, h, w))\n","      output = temp_output.view(bs, ncrops, -1).mean(1)\n","      # calculate the batch loss\n","      # update average test loss \n","      # convert output probabilities to predicted class\n","      _, pred = torch.max(output, 1)    \n","      # compare predictions to true label\n","      correct_tensor = pred.eq(target.data.view_as(pred))\n","      correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n","      # calculate test accuracy for each object class\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tO7YvwCUw2rW"},"source":["test_transforms = transforms.Compose([transforms.Resize(256),\n","                                      transforms.TenCrop(224),\n","                                      transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n","                                      transforms.Lambda(lambda crops: torch.stack([transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])(crop) for crop in crops]))])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A_b9VVICxmXr"},"source":["import natsort as nt\n","from PIL import Image\n","from torch.autograd import Variable \n","def test_model():\n","    data_transforms = transforms.Compose([transforms.Resize(256),\n","                                      transforms.TenCrop(224),\n","                                      transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n","                                      transforms.Lambda(lambda crops: torch.stack([transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])(crop) for crop in crops]))])\n","    #model_ft = torch.load('./models/CustomCNN_model.pth', map_location=device)\n","    \n","    path_test = os.path.join(os.getcwd(), '/content/drive/My Drive/대회2/test123/test')\n","    image_list = nt.natsorted(os.listdir(path_test))\n","    output_list = []\n","    model1.eval()\n","    for i, images in enumerate(image_list):\n","        path_test_image = os.path.join(path_test, images)\n","        image = Image.open(path_test_image)\n","        image = data_transforms(image)\n","        image.unsqueeze_(dim=0)\n","        image = Variable(image)\n","        image = image.cuda()\n","        bs, ncrops, c, h, w = image.size()\n","\n","        torch.no_grad()\n","        temp_output = model1(image.view(-1, c, h, w))\n","        output = temp_output.view(bs, ncrops, -1).mean(1)\n","        _, pred = torch.max(output, 1)  \n","        output_list.append(pred)\n","        \n","    return output_list\n","output = test_model()"],"execution_count":null,"outputs":[]}]}